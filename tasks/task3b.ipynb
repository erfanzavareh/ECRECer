{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Task3. Enzyme Commission Number Assignment\n",
    "\n",
    "> author: Shizhenkun   \n",
    "> email: zhenkun.shi@tib.cas.cn   \n",
    "> date: 2021-12-09  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 80 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "import joblib\n",
    "\n",
    "sys.path.append(\"../tools/\")\n",
    "import funclib\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import benchmark_train as btrain\n",
    "import benchmark_test as btest\n",
    "import config as cfg\n",
    "import benchmark_evaluation as eva\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from pandarallel import pandarallel #  import pandaralle\n",
    "pandarallel.initialize() # init\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 222567\n",
      "test size: 3304\n"
     ]
    }
   ],
   "source": [
    "#read train test data\n",
    "train = pd.read_feather(cfg.DATADIR+'task3/train.feather')\n",
    "test = pd.read_feather(cfg.DATADIR+'task3/test.feather')\n",
    "print('train size: {0}\\ntest size: {1}'.format(len(train), len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 222567/222567 [04:39<00:00, 796.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 3304/3304 [00:00<00:00, 69170.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ec to label dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_set= funclib.split_ecdf_to_single_lines(train)\n",
    "test_set=funclib.split_ecdf_to_single_lines(test)\n",
    "\n",
    "#4. 加载EC号训练数据\n",
    "print('loading ec to label dict')\n",
    "if os.path.exists(cfg.FILE_EC_LABEL_DICT):\n",
    "    dict_ec_label = np.load(cfg.FILE_EC_LABEL_DICT, allow_pickle=True).item()\n",
    "else:\n",
    "    dict_ec_label = btrain.make_ec_label(train_label=train_set['ec_number'], test_label=test_set['ec_number'], file_save= cfg.FILE_EC_LABEL_DICT, force_model_update=cfg.UPDATE_MODEL)\n",
    "    \n",
    "train_set['ec_label'] = train_set.ec_number.parallel_apply(lambda x: dict_ec_label.get(x))\n",
    "test_set['ec_label'] = test_set.ec_number.parallel_apply(lambda x: dict_ec_label.get(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Embedding Comparison\n",
    "### 4.1 one-hot + ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train_set.copy()\n",
    "testset = test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 1500 #定义序列最长的长度\n",
    "trainset.seq = trainset.seq.map(lambda x : x[0:MAX_SEQ_LENGTH].ljust(MAX_SEQ_LENGTH, 'X'))\n",
    "testset.seq = testset.seq.map(lambda x : x[0:MAX_SEQ_LENGTH].ljust(MAX_SEQ_LENGTH, 'X'))\n",
    "f_train = funclib.dna_onehot(trainset) #训练集编码\n",
    "f_test = funclib.dna_onehot(testset) #测试集编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " baslineName \t\t accuracy \t precision-macro \t recall-macro \t f1-macro\n",
      "         knn  \t\t0.068579  \t0.572562 \t\t0.376389 \t0.044914\n"
     ]
    }
   ],
   "source": [
    "# 计算指标\n",
    "X_train = np.array(f_train.iloc[:,2:])\n",
    "X_test = np.array(f_test.iloc[:,2:])\n",
    "Y_train = np.array(trainset.ec_label.astype('int'))\n",
    "Y_test = np.array(testset.ec_label.astype('int'))\n",
    "funclib.run_baseline(X_train, Y_train, X_test, Y_test, type='multi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
