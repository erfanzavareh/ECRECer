{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c2801b5-1a62-4abb-9030-0a6ef709cf24",
   "metadata": {},
   "source": [
    "# Update Production Data and Model\n",
    "\n",
    "> author: Shizhenkun   \n",
    "> email: zhenkun.shi@tib.cas.cn   \n",
    "> date: 2021-12-24  \n",
    "\n",
    "This file contains update codes for the production server. The update should be scheduled every eight weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48326994-9d5b-4905-96ed-36fa3ed72dd9",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96a76da5-08be-41be-b05a-cd68b6d6a789",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 80 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import config as cfg\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"./tools/\")\n",
    "import funclib\n",
    "import exact_ec_from_uniprot as exactec\n",
    "import minitools as mtool\n",
    "import embedding_esm as esmebd\n",
    "# import embedding_unirep as unirep\n",
    "\n",
    "from pandarallel import pandarallel \n",
    "pandarallel.initialize() \n",
    "import benchmark_train as btrain\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe1bf3-da2e-4796-abad-0029f6e81319",
   "metadata": {},
   "source": [
    "## 2. Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ffaeb29-3068-4230-a5a0-13d85cca0f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install axel for download dataset\n",
    "def install_axel():\n",
    "    isExists = !which axel\n",
    "    if 'axel' in str(isExists[0]):\n",
    "        return True\n",
    "    else:\n",
    "        !sudo apt install axel -y\n",
    "\n",
    "# add missing '-' for ec number\n",
    "def refill_ec(ec):   \n",
    "    if ec == '-':\n",
    "        return ec\n",
    "    levelArray = ec.split('.')\n",
    "    if  levelArray[3]=='':\n",
    "        levelArray[3] ='-'\n",
    "    ec = '.'.join(levelArray)\n",
    "    return ec\n",
    "\n",
    "def specific_ecs(ecstr):\n",
    "    if '-' not in ecstr or len(ecstr)<4:\n",
    "        return ecstr\n",
    "    ecs = ecstr.split(',')\n",
    "    if len(ecs)==1:\n",
    "        return ecstr\n",
    "    \n",
    "    reslist=[]\n",
    "    \n",
    "    for ec in ecs:\n",
    "        recs = ecs.copy()\n",
    "        recs.remove(ec)\n",
    "        ecarray = np.array([x.split('.') for x in recs])\n",
    "        \n",
    "        if '-' not in ec:\n",
    "            reslist +=[ec]\n",
    "            continue\n",
    "        linearray= ec.split('.')\n",
    "        if linearray[1] == '-':\n",
    "            #l1 in l1s and l2 not empty\n",
    "            if (linearray[0] in  ecarray[:,0]) and (len(set(ecarray[:,0]) - set({'-'}))>0):\n",
    "                continue\n",
    "        if linearray[2] == '-':\n",
    "            # l1, l2 in l1s l2s, l3 not empty\n",
    "            if (linearray[0] in  ecarray[:,0]) and (linearray[1] in  ecarray[:,1]) and (len(set(ecarray[:,2]) - set({'-'}))>0):\n",
    "                continue\n",
    "        if linearray[3] == '-':\n",
    "            # l1, l2, l3 in l1s l2s l3s, l4 not empty\n",
    "            if (linearray[0] in  ecarray[:,0]) and (linearray[1] in  ecarray[:,1]) and (linearray[2] in  ecarray[:,2]) and (len(set(ecarray[:,3]) - set({'-'}))>0):\n",
    "                continue\n",
    "                \n",
    "        reslist +=[ec]\n",
    "    return ','.join(reslist)\n",
    "\n",
    "#format ec\n",
    "def format_ec(ecstr):\n",
    "    ecArray= ecstr.split(',')\n",
    "    ecArray=[x.strip() for x in ecArray] #strip blank\n",
    "    ecArray=[refill_ec(x) for x in ecArray] #format ec to full\n",
    "    ecArray = list(set(ecArray)) # remove duplicates\n",
    "    \n",
    "    return ','.join(ecArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4912f-59f0-4555-9172-edcb548056e1",
   "metadata": {},
   "source": [
    "## 3. Download latest data from unisprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a53aba9e-9232-44a2-a554-8f670e536fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download location ./tmp\n",
    "\n",
    "! mv $cfg.DATADIR'uniprot_sprot_latest.dat.gz' $cfg.TEMPDIR$currenttime'_uniprot_sprot_latest.dat.gz'\n",
    "install_axel()\n",
    "! axel -n 10 https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.dat.gz -o ./data/uniprot_sprot_latest.dat.gz -q -c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7df6ac-7247-4045-bca2-58277bb61d24",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afee4738-dc8e-4637-8d7f-b288035ab3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "565928it [04:38, 2032.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished use time 267.457 s\n"
     ]
    }
   ],
   "source": [
    "exactec.run_exact_task(infile=cfg.DATADIR+'uniprot_sprot_latest.dat.gz', outfile=cfg.DATADIR+'sprot_latest.tsv')\n",
    "\n",
    "#加载数据并转换时间格式\n",
    "sprot_latest = pd.read_csv(cfg.DATADIR+'sprot_latest.tsv', sep='\\t',header=0) #读入文件\n",
    "sprot_latest = mtool.convert_DF_dateTime(inputdf = sprot_latest)\n",
    "\n",
    "sprot_latest.drop_duplicates(subset=['seq'], keep='first', inplace=True)\n",
    "sprot_latest.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#sprot_latest format EC\n",
    "sprot_latest['ec_number'] = sprot_latest.ec_number.parallel_apply(lambda x: format_ec(x))\n",
    "sprot_latest['ec_number'] = sprot_latest.ec_number.parallel_apply(lambda x: specific_ecs(x))\n",
    "sprot_latest['functionCounts'] = sprot_latest.ec_number.parallel_apply(lambda x: 0 if x=='-'  else len(x.split(',')))\n",
    "\n",
    "# Trim Strging\n",
    "with pd.option_context('mode.chained_assignment', None):\n",
    "    sprot_latest.ec_number = sprot_latest.ec_number.parallel_apply(lambda x : str(x).strip()) #ec trim\n",
    "    sprot_latest.seq = sprot_latest.seq.parallel_apply(lambda x : str(x).strip()) #seq trim\n",
    "\n",
    "sprot_latest.to_feather(cfg.DATADIR + 'latest_sprot.feather')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef3c2fa-5187-404d-9df3-bbc657287910",
   "metadata": {},
   "source": [
    "## 5. Caculation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4d7fc8a-65ad-4248-a2d2-649e0b813745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 477917\n"
     ]
    }
   ],
   "source": [
    "train= pd.read_feather(cfg.DATADIR + 'latest_sprot.feather')\n",
    "print('train size: {0}'.format(len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5fe8cb0-9e00-4f0c-9045-bef4d106204e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat '/home/shizhenkun/codebase/DMLF/data/sprot_latest_rep0.feather': No such file or directory\n",
      "mv: cannot stat '/home/shizhenkun/codebase/DMLF/data/sprot_latest_rep32.feather': No such file or directory\n",
      "mv: cannot stat '/home/shizhenkun/codebase/DMLF/data/sprot_latest_rep33.feather': No such file or directory\n",
      "mv: cannot stat '/home/shizhenkun/codebase/DMLF/data/sprot_latest_unirep.feather': No such file or directory\n",
      "Transferred model to GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████████████████████████████████████████▉                        | 351401/477917 [4:36:51<1:24:55, 24.83it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 75%|████████████████████████████████████████████████████████████████████▋                      | 360810/477917 [4:43:53<1:17:42, 25.11it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! mv $cfg.DATADIR'sprot_latest_rep0.feather' $cfg.DATADIR'featureBank/sprot_latest_rep0.feather'\n",
    "! mv $cfg.DATADIR'sprot_latest_rep32.feather' $cfg.DATADIR'featureBank/sprot_latest_rep32.feather'\n",
    "! mv $cfg.DATADIR'sprot_latest_rep33.feather' $cfg.DATADIR'featureBank/sprot_latest_rep33.feather'\n",
    "! mv $cfg.DATADIR'sprot_latest_unirep.feather' $cfg.DATADIR'featureBank/sprot_latest_unirep.feather'\n",
    "\n",
    "# !pip install fair-esm\n",
    "tr_rep0, tr_rep32, tr_rep33 = esmebd.get_rep_multi_sequence(sequences=train, model='esm1b_t33_650M_UR50S',seqthres=1022)\n",
    "tr_rep0.to_feather(cfg.DATADIR + 'sprot_latest_rep0.feather')\n",
    "tr_rep32.to_feather(cfg.DATADIR + 'sprot_latest_rep32.feather')\n",
    "tr_rep33.to_feather(cfg.DATADIR + 'sprot_latest_rep33.feather')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9b2137c-ae11-42f7-a8da-fa699cca7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_esm_latest = pd.read_feather(cfg.DATADIR + 'sprot_latest_rep32.feather')\n",
    "train_esm_latest = train.merge(train_esm_latest, on='id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da8140c-e00f-413b-b7c8-94607a44ea59",
   "metadata": {},
   "source": [
    "## 6. Split X Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ee3dbe-519c-471e-aa60-feecf84db6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████▍| 230124/231373 [05:15<00:04, 251.08it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# task 1\n",
    "X_train_task1 = np.array(train_esm_latest.iloc[:,12:])\n",
    "Y_train_task1 = np.array(train_esm_latest.isenzyme.astype('int')).flatten()\n",
    "train_enzyme = train_esm_latest[train_esm_latest.isenzyme].reset_index(drop=True)\n",
    "\n",
    "# task 2\n",
    "X_train_task2_s = np.array(train_enzyme.iloc[:,12:])\n",
    "Y_train_task2_s = train_enzyme.functionCounts.apply(lambda x : 0 if x==1 else 1).astype('int').values\n",
    "\n",
    "train_task2M=train_enzyme[train_enzyme.functionCounts>=2].reset_index(drop=True)\n",
    "X_train_task2_m = np.array(train_task2M.iloc[:,12:])\n",
    "Y_train_task2_m = np.array(train_task2M.functionCounts.astype('int')-2).flatten()\n",
    "\n",
    "#task 3\n",
    "train_set_task3= funclib.split_ecdf_to_single_lines(train_enzyme.iloc[:,np.r_[0,10,5]])\n",
    "train_set_task3=train_set_task3.merge(train_esm_latest.iloc[:,np.r_[0,12:1292]], on='id', how='left')\n",
    "\n",
    "#4. 加载EC号训练数据\n",
    "print('loading ec to label dict')\n",
    "dict_ec_label = btrain.make_ec_label(train_label=train_set_task3['ec_number'], test_label=train_set_task3['ec_number'], file_save= cfg.FILE_EC_LABEL_DICT, force_model_update=cfg.UPDATE_MODEL)\n",
    "\n",
    "train_set_task3['ec_label']=train_set_task3.ec_number.parallel_apply(lambda x: dict_ec_label.get(x))    \n",
    "X_train_task3 = np.array(train_set_task3.iloc[:,3:])\n",
    "Y_train_task3 = np.array(train_set_task3.ec_label.astype('int')).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e89d3-b5f5-4897-bb23-afaa0db3d388",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df91a62a-0eee-44b1-9b0a-65b5e60d8bc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_92638/1952265788.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Task 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgroundtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunclib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknnmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_task1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_task1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_task1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_task1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mISENZYME_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "# Task 1\n",
    "groundtruth, predict, predictprob, model = funclib.knnmain(X_train_task1, Y_train_task1, X_train_task1.iloc[0:10,:], Y_train_task1.iloc[0:10,:], type='binary')\n",
    "joblib.dump(model, cfg.ISENZYME_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c6fe4-94de-4b69-be93-427535de880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth, predict, predictprob, model = funclib.xgmain(X_train_task2_s, Y_train_task2_s, X_train_task2_s.iloc[0:10,:], Y_train_task2_s.iloc[0:10,:], type='binary')\n",
    "joblib.dump(model, cfg.MODELDIR+'/single_multi.model')\n",
    "\n",
    "groundtruth, predict, predictprob, model = funclib.xgmain(X_train_task2_m, Y_train_task2_m, X_train_task2_m.iloc[0:10,:], Y_train_task2_m.iloc[0:10,:], type='multi')\n",
    "joblib.dump(model, cfg.MODELDIR+'/multi_many.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a3c00-66cf-4ed1-9deb-c03dddbd4035",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.FEATURE_NUM = 1280\n",
    "#train\n",
    "bcommon.prepare_slice_file(x_data=X_train_task3, y_data=Y_train_task3, x_file=cfg.DATADIR+'slice_train_x_esm32_latest.txt', y_file=cfg.DATADIR+'slice_train_y_esm32_latest.txt', ec_label_dict=dict_ec_label)\n",
    "btrain.train_ec_slice(trainX=cfg.DATADIR+'slice_train_x_esm32_latest.txt', trainY=cfg.DATADIR+'slice_train_y_esm32_latest.txt', modelPath=cfg.MODELDIR+'/slice_esm32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15025c23-6284-4086-ac63-8c3973db169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_sprot = pd.read_feather(cfg.FILE_LATEST_SPROT_FEATHER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
