{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 104 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib, os,time, argparse\n",
    "import benchmark_common as bcommon\n",
    "import config as cfg\n",
    "import benchmark_test as btest\n",
    "import benchmark_train as btrain\n",
    "import benchmark_evaluation as eva\n",
    "import tools.funclib as funclib\n",
    "import tools.embedding_esm as esmebd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gc import callbacks\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.callback import EarlyStopping\n",
    "\n",
    "from pandarallel import pandarallel #  import pandaralle\n",
    "pandarallel.initialize() \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 loading task data\n"
     ]
    }
   ],
   "source": [
    "print('step 1 loading task data')\n",
    "\n",
    "data_task1_train = pd.read_feather(cfg.FILE_TASK1_TRAIN)\n",
    "data_task2_train = pd.read_feather(cfg.FILE_TASK2_TRAIN)\n",
    "data_task3_train = pd.read_feather(cfg.FILE_TASK3_TRAIN)\n",
    "\n",
    "data_task1_test = pd.read_feather(cfg.FILE_TASK1_TEST)\n",
    "data_task2_test = pd.read_feather(cfg.FILE_TASK2_TEST)\n",
    "data_task3_test = pd.read_feather(cfg.FILE_TASK3_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIAMOND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diamond Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write finished\n",
      "Write finished\n",
      "diamond makedb --in /tmp/train.fasta -d /tmp/train.dmnd --quiet\n",
      "diamond blastp -d /tmp/train.dmnd  -q  /tmp/test.fasta -o /tmp/test_fasta_results.tsv -b5 -c1 -k 1 --quiet\n",
      "baslineName \t\t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t \t confusion Matrix\n",
      "Diamond \t\t0.677030 \t0.629801 \t\t0.751150 \t0.798865 \t0.704330 \t tp: 4083 fp: 2400 fn: 1028 tn: 3103\n"
     ]
    }
   ],
   "source": [
    "diamond_task1 = funclib.getblast(train=data_task1_train[['id','seq']], test=data_task1_test[['id','seq']])\n",
    "\n",
    "res_task1_diamond =diamond_task1[['id','sseqid']].merge(data_task1_train[['id','isenzyme']], how='left', left_on='sseqid', right_on='id')\n",
    "res_task1_diamond = res_task1_diamond[['id_x', 'isenzyme']].rename(columns={'id_x':'id','isenzyme':'isenzyme_pred'})\n",
    "res_task1_diamond = data_task1_test.merge(res_task1_diamond, how='left', on='id')\n",
    "res_task1_diamond['isenzyme_pred_full']=res_task1_diamond.apply(lambda x : x.isenzyme_pred if (str(x.isenzyme_pred)!='nan') else ( True if x.isenzyme==False else False)  , axis=1)\n",
    "\n",
    "print('baslineName', '\\t\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', '\\t confusion Matrix')\n",
    "eva.caculateMetrix(groundtruth=res_task1_diamond.isenzyme, predict=res_task1_diamond.isenzyme_pred_full, baselineName='Diamond', type='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diamond Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write finished\n",
      "Write finished\n",
      "diamond makedb --in /tmp/train.fasta -d /tmp/train.dmnd --quiet\n",
      "diamond blastp -d /tmp/train.dmnd  -q  /tmp/test.fasta -o /tmp/test_fasta_results.tsv -b5 -c1 -k 1 --quiet\n",
      " baslineName \t\t accuracy \t precision-macro \t recall-macro \t f1-macro\n",
      "     Diamond  \t\t0.744277  \t0.434697 \t\t0.350342 \t0.273826\n"
     ]
    }
   ],
   "source": [
    "diamond_task2 = funclib.getblast(train=data_task2_train[['id','seq']], test=data_task2_test[['id','seq']])\n",
    "res_task2_diamond = diamond_task2[['id','sseqid']].merge(data_task2_train[['id','functionCounts']], how='left', left_on='sseqid', right_on='id')\n",
    "res_task2_diamond = res_task2_diamond[['id_x', 'functionCounts']].rename(columns={'id_x':'id','functionCounts':'functionCounts_diamond'})\n",
    "res_task2_diamond = data_task2_test.merge( res_task2_diamond, on='id', how='left')\n",
    "res_task2_diamond = res_task2_diamond.fillna(-1)\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "eva.caculateMetrix(groundtruth=res_task2_diamond.functionCounts, predict=res_task2_diamond.functionCounts_diamond, baselineName='Diamond', type='multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diamond Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write finished\n",
      "Write finished\n",
      "diamond makedb --in /tmp/train.fasta -d /tmp/train.dmnd --quiet\n",
      "diamond blastp -d /tmp/train.dmnd  -q  /tmp/test.fasta -o /tmp/test_fasta_results.tsv -b5 -c1 -k 1 --quiet\n",
      " baslineName \t\t accuracy \t precision-macro \t recall-macro \t f1-macro\n",
      "     Diamond  \t\t0.438270  \t0.661079 \t\t0.501091 \t0.226622\n"
     ]
    }
   ],
   "source": [
    "diamond_task3 = funclib.getblast(train=data_task3_train[['id','seq']], test=data_task3_test[['id','seq']])\n",
    "res_task3_diamond = diamond_task3[['id','sseqid']].merge(data_task3_train[['id','ec_number']], how='left', left_on='sseqid', right_on='id')\n",
    "res_task3_diamond = res_task3_diamond[['id_x', 'ec_number']].rename(columns={'id_x':'id','ec_number':'ec_number_diamond'})\n",
    "\n",
    "res_task3_diamond = data_task3_test.merge( res_task3_diamond, on='id', how='left')\n",
    "res_task3_diamond = res_task3_diamond.fillna('-')\n",
    "\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "eva.caculateMetrix(groundtruth=res_task3_diamond.ec_number, predict=res_task3_diamond.ec_number_diamond, baselineName='Diamond', type='multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepEC\n",
    "### Run DeepEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate deepec\n",
    "!python ./baselines/deepec/deepec.py -i ./datasets/task1/test.fasta -o ./results/deepec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task1:\n",
      "----------------\n",
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t \t confusion Matrix\n",
      "deepec \t\t0.638308 \t0.944134 \t\t0.590612 \t0.264527 \t0.413266 \t tp: 1352 fp: 80 fn: 3759 tn: 5423\n",
      "\n",
      "task2:\n",
      "----------------\n",
      " baslineName \t\t accuracy \t precision-macro \t recall-macro \t f1-macro\n",
      "      deepec  \t\t0.906281  \t0.817691 \t\t0.135362 \t0.138948\n",
      "\n",
      "task3:\n",
      "----------------\n",
      " baslineName \t\t accuracy \t precision-macro \t recall-macro \t f1-macro\n",
      "      deepec  \t\t0.104872  \t0.791039 \t\t0.287901 \t0.121086\n"
     ]
    }
   ],
   "source": [
    "res_deepec = pd.read_csv(cfg.FILE_DEEPEC_RESULTS, sep='\\t',names=['id', 'ec_number'], header=0 )\n",
    "res_deepec.ec_number=res_deepec.apply(lambda x: x['ec_number'].replace('EC:',''), axis=1)\n",
    "res_deepec.columns = ['id','ec_deepec']\n",
    "\n",
    "res = []\n",
    "for index, group in  res_deepec.groupby('id'):\n",
    "    if len(group)==1:\n",
    "        res = res + [[group.id.values[0], group.ec_deepec.values[0]]]\n",
    "    else:\n",
    "        ecs_str = ','.join(group.ec_deepec.values)\n",
    "        res = res +[[group.id.values[0],ecs_str]] \n",
    "res_deepec = pd.DataFrame(res, columns=['id', 'ec_deepec'])\n",
    "\n",
    "\n",
    "res_deepec_task1=data_task1_test.merge(res_deepec, on='id', how='left')\n",
    "res_deepec_task1['isenzyme_pred']=res_deepec_task1.ec_deepec.apply(lambda x: True if str(x)!='nan' else False)\n",
    "\n",
    "print('task1:\\n----------------')\n",
    "print('baslineName', '\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', '\\t confusion Matrix')\n",
    "eva.caculateMetrix(groundtruth=res_deepec_task1.isenzyme, predict=res_deepec_task1.isenzyme_pred, baselineName='deepec', type='binary')\n",
    "\n",
    "print('\\ntask2:\\n----------------')\n",
    "\n",
    "res_deepec_task2=data_task2_test.merge(res_deepec, on='id', how='left')\n",
    "res_deepec_task2=res_deepec_task2.fillna('-')\n",
    "res_deepec_task2['functionCounts_deepec'] =res_deepec_task2.ec_deepec.apply(lambda x: len(x.split(',')))\n",
    "\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "eva.caculateMetrix(groundtruth=res_deepec_task2.functionCounts, predict=res_deepec_task2.functionCounts_deepec, baselineName='deepec', type='multi')\n",
    "\n",
    "print('\\ntask3:\\n----------------')\n",
    "res_deepec_task3 = data_task3_test.merge(res_deepec, on='id', how='left')\n",
    "res_deepec_task3=res_deepec_task3.fillna('-')\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "eva.caculateMetrix(groundtruth=res_deepec_task3.ec_number, predict=res_deepec_task3.ec_deepec, baselineName='deepec', type='multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatFam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task1:\n",
      "----------------\n",
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t \t confusion Matrix\n",
      "catfam \t\t0.594404 \t0.927813 \t\t0.561931 \t0.171004 \t0.288782 \t tp: 874 fp: 68 fn: 4237 tn: 5435\n",
      "\n",
      "task2:\n",
      "----------------\n",
      " baslineName \t\t accuracy \t precision-macro \t recall-macro \t f1-macro\n",
      "      catfam  \t\t0.910194  \t0.662225 \t\t0.159200 \t0.174859\n",
      "\n",
      "task3:\n",
      "----------------\n",
      "      catfam  \t\t0.084328  \t0.885812 \t\t0.191622 \t0.101330\n"
     ]
    }
   ],
   "source": [
    "res_catfam = pd.read_csv(cfg.RESULTSDIR+'catfam/catfam.txt', sep='\\t', names=['id', 'ec_catfam'])\n",
    "res = []\n",
    "for index, group in  res_catfam.groupby('id'):\n",
    "    if len(group)==1:\n",
    "        res = res + [[group.id.values[0], group.ec_catfam.values[0]]]\n",
    "    else:\n",
    "        ecs_str = ','.join(group.ec_catfam.values)\n",
    "        res = res +[[group.id.values[0],ecs_str]] \n",
    "res_catfam = pd.DataFrame(res, columns=['id', 'ec_catfam'])\n",
    "res_catfam = res_catfam.fillna('-')\n",
    "res_catfam['isenzyme_catfam']=res_catfam.ec_catfam.apply(lambda x: True if str(x)!='-' else False)\n",
    "res_catfam['functionCounts_catfam'] = res_catfam.ec_catfam.apply(lambda x :len(str(x).split(',')))\n",
    "\n",
    "print('task1:\\n----------------')\n",
    "res_catfam_task1=data_task1_test.merge(res_catfam, on='id', how='left')\n",
    "print('baslineName', '\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', '\\t confusion Matrix')\n",
    "eva.caculateMetrix(groundtruth=res_catfam_task1.isenzyme, predict=res_catfam_task1.isenzyme_catfam, baselineName='catfam', type='binary')\n",
    "\n",
    "print('\\ntask2:\\n----------------')\n",
    "res_catfam_task2=data_task2_test.merge(res_catfam, on='id', how='left')\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "eva.caculateMetrix(groundtruth=res_catfam_task2.functionCounts, predict=res_catfam_task2.functionCounts_catfam, baselineName='catfam', type='multi')\n",
    "\n",
    "print('\\ntask3:\\n----------------')\n",
    "res_catfam_task3=data_task3_test.merge(res_catfam, on='id', how='left')\n",
    "eva.caculateMetrix(groundtruth=res_catfam_task3.ec_number, predict=res_catfam_task3.ec_catfam, baselineName='catfam', type='multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRIAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ec_priam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, ec_priam]\n",
       "Index: []"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva.load_praim_res(resfile=cfg.RESULTSDIR+'priam/PRIAM_20221010101922/ANNOTATION/sequenceECs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A0A0D1DNX1    6\n",
       "I1S489        4\n",
       "B9VUU3        4\n",
       "Q5AV07        4\n",
       "Q68T42        4\n",
       "             ..\n",
       "F1SY49        1\n",
       "A0A0H3JXA3    1\n",
       "A0A2I1BT09    1\n",
       "G3V6U9        1\n",
       "B7MMH5        1\n",
       "Name: id, Length: 5111, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_catfam_task2.id.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0598356972e9a098a4a3756f1f561f75f6bcc730be3bc51870d213558f68c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
