{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 104 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib, os,time, argparse\n",
    "import benchmark_common as bcommon\n",
    "import config as cfg\n",
    "import benchmark_test as btest\n",
    "import benchmark_train as btrain\n",
    "import benchmark_evaluation as eva\n",
    "import tools.funclib as funclib\n",
    "import tools.embedding_esm as esmebd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gc import callbacks\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.callback import EarlyStopping\n",
    "\n",
    "from pandarallel import pandarallel #  import pandaralle\n",
    "pandarallel.initialize() \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 loading task data\n"
     ]
    }
   ],
   "source": [
    "print('step 1 loading task data')\n",
    "\n",
    "data_task1_train = pd.read_feather(cfg.FILE_TASK1_TRAIN)\n",
    "data_task2_train = pd.read_feather(cfg.FILE_TASK2_TRAIN)\n",
    "data_task3_train = pd.read_feather(cfg.FILE_TASK3_TRAIN)\n",
    "\n",
    "data_task1_test = pd.read_feather(cfg.FILE_TASK1_TEST)\n",
    "data_task2_test = pd.read_feather(cfg.FILE_TASK2_TEST)\n",
    "data_task3_test = pd.read_feather(cfg.FILE_TASK3_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DIAMOND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write finished\n",
      "Write finished\n",
      "diamond makedb --in /tmp/train.fasta -d /tmp/train.dmnd --quiet\n",
      "diamond blastp -d /tmp/train.dmnd  -q  /tmp/test.fasta -o /tmp/test_fasta_results.tsv -b5 -c1 -k 1 --quiet\n",
      "baslineName \t\t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t \t confusion Matrix\n",
      "Diamond \t\t0.677030 \t0.629801 \t\t0.751150 \t0.798865 \t0.704330 \t tp: 4083 fp: 2400 fn: 1028 tn: 3103\n"
     ]
    }
   ],
   "source": [
    "diamond_task1 = funclib.getblast(train=data_task1_train[['id','seq']], test=data_task1_test[['id','seq']])\n",
    "\n",
    "res_task1_diamond =diamond_task1[['id','sseqid']].merge(data_task1_train[['id','isenzyme']], how='left', left_on='sseqid', right_on='id')\n",
    "res_task1_diamond = res_task1_diamond[['id_x', 'isenzyme']].rename(columns={'id_x':'id','isenzyme':'isenzyme_pred'})\n",
    "res_task1_diamond = data_task1_test.merge(res_task1_diamond, how='left', on='id')\n",
    "res_task1_diamond['isenzyme_pred_full']=res_task1_diamond.apply(lambda x : x.isenzyme_pred if (str(x.isenzyme_pred)!='nan') else ( True if x.isenzyme==False else False)  , axis=1)\n",
    "print('task1:\\n----------------')\n",
    "print('baslineName', '\\t\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', '\\t confusion Matrix')\n",
    "eva.caculateMetrix(groundtruth=res_task1_diamond.isenzyme, predict=res_task1_diamond.isenzyme_pred_full, baselineName='Diamond', type='binary')\n",
    "\n",
    "print('\\ntask2:\\n----------------')\n",
    "\n",
    "diamond_task2 = funclib.getblast(train=data_task2_train[['id','seq']], test=data_task2_test[['id','seq']])\n",
    "res_task2_diamond = diamond_task2[['id','sseqid']].merge(data_task2_train[['id','functionCounts']], how='left', left_on='sseqid', right_on='id')\n",
    "res_task2_diamond = res_task2_diamond[['id_x', 'functionCounts']].rename(columns={'id_x':'id','functionCounts':'functionCounts_diamond'})\n",
    "res_task2_diamond = data_task2_test.merge( res_task2_diamond, on='id', how='left')\n",
    "res_task2_diamond = res_task2_diamond.fillna(-1)\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "eva.caculateMetrix(groundtruth=res_task2_diamond.functionCounts, predict=res_task2_diamond.functionCounts_diamond, baselineName='Diamond', type='multi')\n",
    "\n",
    "diamond_task3 = funclib.getblast(train=data_task3_train[['id','seq']], test=data_task3_test[['id','seq']])\n",
    "res_task3_diamond = diamond_task3[['id','sseqid']].merge(data_task3_train[['id','ec_number']], how='left', left_on='sseqid', right_on='id')\n",
    "res_task3_diamond = res_task3_diamond[['id_x', 'ec_number']].rename(columns={'id_x':'id','ec_number':'ec_number_diamond'})\n",
    "\n",
    "res_task3_diamond = data_task3_test.merge( res_task3_diamond, on='id', how='left')\n",
    "res_task3_diamond = res_task3_diamond.fillna('-')\n",
    "print('\\ntask3:\\n----------------')\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "eva.caculateMetrix(groundtruth=res_task3_diamond.ec_number, predict=res_task3_diamond.ec_number_diamond, baselineName='Diamond', type='multi')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ECPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ecpred = pd.read_csv(file_ecpred, sep='\\t', header=0)\n",
    "res_ecpred['isemzyme_ecpred'] = ''\n",
    "with pd.option_context('mode.chained_assignment', None):\n",
    "    res_ecpred.isemzyme_ecpred[res_ecpred['EC Number']=='non Enzyme'] = False\n",
    "    res_ecpred.isemzyme_ecpred[res_ecpred['EC Number']!='non Enzyme'] = True\n",
    "    \n",
    "res_ecpred.columns = ['id','ec_ecpred', 'conf', 'isemzyme_ecpred']\n",
    "res_ecpred = res_ecpred.iloc[:,np.r_[0,1,3]]\n",
    "res_ecpred['functionCounts_ecpred'] = res_ecpred.ec_ecpred.apply(lambda x :len(str(x).split(',')))\n",
    "big_res = big_res.merge(res_ecpred, on='id', how='left').drop_duplicates(subset='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DeepEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task1:\n",
      "----------------\n",
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t \t confusion Matrix\n",
      "deepec \t\t0.638308 \t0.944134 \t\t0.590612 \t0.264527 \t0.413266 \t tp: 1352 fp: 80 fn: 3759 tn: 5423\n",
      "\n",
      "task2:\n",
      "----------------\n",
      " baslineName \t\t accuracy \t precision-macro \t recall-macro \t f1-macro\n",
      "      deepec  \t\t0.906281  \t0.817691 \t\t0.135362 \t0.138948\n",
      "\n",
      "task3:\n",
      "----------------\n",
      " baslineName \t\t accuracy \t precision-macro \t recall-macro \t f1-macro\n",
      "      deepec  \t\t0.104872  \t0.791039 \t\t0.287901 \t0.121086\n"
     ]
    }
   ],
   "source": [
    "# !conda activate deepec\n",
    "# !python ./baselines/deepec/deepec.py -i ./datasets/task1/test.fasta -o ./results/deepec/\n",
    "\n",
    "res_deepec = pd.read_csv(cfg.FILE_DEEPEC_RESULTS, sep='\\t',names=['id', 'ec_number'], header=0 )\n",
    "res_deepec.ec_number=res_deepec.apply(lambda x: x['ec_number'].replace('EC:',''), axis=1)\n",
    "res_deepec.columns = ['id','ec_deepec']\n",
    "\n",
    "res = []\n",
    "for index, group in  res_deepec.groupby('id'):\n",
    "    if len(group)==1:\n",
    "        res = res + [[group.id.values[0], group.ec_deepec.values[0]]]\n",
    "    else:\n",
    "        ecs_str = ','.join(group.ec_deepec.values)\n",
    "        res = res +[[group.id.values[0],ecs_str]] \n",
    "res_deepec = pd.DataFrame(res, columns=['id', 'ec_deepec'])\n",
    "\n",
    "\n",
    "res_deepec_task1=data_task1_test.merge(res_deepec, on='id', how='left')\n",
    "res_deepec_task1['isenzyme_pred']=res_deepec_task1.ec_deepec.apply(lambda x: True if str(x)!='nan' else False)\n",
    "\n",
    "print('task1:\\n----------------')\n",
    "print('baslineName', '\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', '\\t confusion Matrix')\n",
    "eva.caculateMetrix(groundtruth=res_deepec_task1.isenzyme, predict=res_deepec_task1.isenzyme_pred, baselineName='deepec', type='binary')\n",
    "\n",
    "print('\\ntask2:\\n----------------')\n",
    "\n",
    "res_deepec_task2=data_task2_test.merge(res_deepec, on='id', how='left')\n",
    "res_deepec_task2=res_deepec_task2.fillna('-')\n",
    "res_deepec_task2['functionCounts_deepec'] =res_deepec_task2.ec_deepec.apply(lambda x: len(x.split(',')))\n",
    "\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "eva.caculateMetrix(groundtruth=res_deepec_task2.functionCounts, predict=res_deepec_task2.functionCounts_deepec, baselineName='deepec', type='multi')\n",
    "\n",
    "print('\\ntask3:\\n----------------')\n",
    "res_deepec_task3 = data_task3_test.merge(res_deepec, on='id', how='left')\n",
    "res_deepec_task3=res_deepec_task3.fillna('-')\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "eva.caculateMetrix(groundtruth=res_deepec_task3.ec_number, predict=res_deepec_task3.ec_deepec, baselineName='deepec', type='multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CatFam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task1:\n",
      "----------------\n",
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t \t confusion Matrix\n",
      "catfam \t\t0.594404 \t0.927813 \t\t0.561931 \t0.171004 \t0.288782 \t tp: 874 fp: 68 fn: 4237 tn: 5435\n",
      "\n",
      "task2:\n",
      "----------------\n",
      " baslineName \t\t accuracy \t precision-macro \t recall-macro \t f1-macro\n",
      "      catfam  \t\t0.910194  \t0.662225 \t\t0.159200 \t0.174859\n",
      "\n",
      "task3:\n",
      "----------------\n",
      "      catfam  \t\t0.084328  \t0.885812 \t\t0.191622 \t0.101330\n"
     ]
    }
   ],
   "source": [
    "res_catfam = pd.read_csv(cfg.RESULTSDIR+'catfam/catfam.txt', sep='\\t', names=['id', 'ec_catfam'])\n",
    "res = []\n",
    "for index, group in  res_catfam.groupby('id'):\n",
    "    if len(group)==1:\n",
    "        res = res + [[group.id.values[0], group.ec_catfam.values[0]]]\n",
    "    else:\n",
    "        ecs_str = ','.join(group.ec_catfam.values)\n",
    "        res = res +[[group.id.values[0],ecs_str]] \n",
    "res_catfam = pd.DataFrame(res, columns=['id', 'ec_catfam'])\n",
    "res_catfam = res_catfam.fillna('-')\n",
    "res_catfam['isenzyme_catfam']=res_catfam.ec_catfam.apply(lambda x: True if str(x)!='-' else False)\n",
    "res_catfam['functionCounts_catfam'] = res_catfam.ec_catfam.apply(lambda x :len(str(x).split(',')))\n",
    "\n",
    "print('task1:\\n----------------')\n",
    "res_catfam_task1=data_task1_test.merge(res_catfam, on='id', how='left')\n",
    "print('baslineName', '\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', '\\t confusion Matrix')\n",
    "eva.caculateMetrix(groundtruth=res_catfam_task1.isenzyme, predict=res_catfam_task1.isenzyme_catfam, baselineName='catfam', type='binary')\n",
    "\n",
    "print('\\ntask2:\\n----------------')\n",
    "res_catfam_task2=data_task2_test.merge(res_catfam, on='id', how='left')\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "eva.caculateMetrix(groundtruth=res_catfam_task2.functionCounts, predict=res_catfam_task2.functionCounts_catfam, baselineName='catfam', type='multi')\n",
    "\n",
    "print('\\ntask3:\\n----------------')\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "res_catfam_task3=data_task3_test.merge(res_catfam, on='id', how='left')\n",
    "eva.caculateMetrix(groundtruth=res_catfam_task3.ec_number, predict=res_catfam_task3.ec_catfam, baselineName='catfam', type='multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PRIAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task1:\n",
      "----------------\n",
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t \t confusion Matrix\n",
      "priam \t\t0.747315 \t0.678001 \t\t0.872065 \t0.905107 \t0.775264 \t tp: 4626 fp: 2197 fn: 485 tn: 3306\n",
      "\n",
      "task2:\n",
      "----------------\n",
      " baslineName \t\t accuracy \t precision-macro \t recall-macro \t f1-macro\n",
      "       priam  \t\t0.132655  \t0.009457 \t\t0.930938 \t0.003176\n",
      "\n",
      "task3:\n",
      "----------------\n",
      " baslineName \t\t accuracy \t precision-macro \t recall-macro \t f1-macro\n",
      "       priam  \t\t0.045197  \t0.250324 \t\t0.752550 \t0.014136\n"
     ]
    }
   ],
   "source": [
    "res_priam = eva.load_praim_res(resfile=cfg.RESULTSDIR+'priam/PRIAM_20221011103347/ANNOTATION/sequenceECs.txt')\n",
    "\n",
    "\n",
    "res_priam['isenzyme_priam'] = res_priam.ec_priam.apply(lambda x: True if str(x)!='nan' else False)\n",
    "res_priam['functionCounts_priam'] = res_priam.ec_priam.apply(lambda x :len(str(x).split(',')))\n",
    "\n",
    "print('task1:\\n----------------')\n",
    "res_priam_task1=data_task1_test.merge(res_priam, on='id', how='left')\n",
    "# res_priam_task1['isenzyme_priam']=res_priam_task1.apply(lambda x: x.isenzyme_priam if x.isenzyme_priam==True else (False if x.isenzyme else True), axis=1)\n",
    "res_priam_task1.isenzyme_priam = res_priam_task1.isenzyme_priam.fillna(False)\n",
    "print('baslineName', '\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', '\\t confusion Matrix')\n",
    "eva.caculateMetrix(groundtruth=res_priam_task1.isenzyme, predict=res_priam_task1.isenzyme_priam, baselineName='priam', type='binary')\n",
    "\n",
    "print('\\ntask2:\\n----------------')\n",
    "res_priam_task2=data_task2_test.merge(res_priam, on='id', how='left')\n",
    "res_priam_task2.functionCounts_priam = res_priam_task2.functionCounts_priam.fillna(0)\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "eva.caculateMetrix(groundtruth=res_priam_task2.functionCounts, predict=res_priam_task2.functionCounts_priam, baselineName='priam', type='multi')\n",
    "\n",
    "print('\\ntask3:\\n----------------')\n",
    "res_priam_task3=data_task3_test.merge(res_priam, on='id', how='left')\n",
    "res_priam_task3.ec_priam = res_priam_task3.ec_priam.fillna('-')\n",
    "print('%12s'%'baslineName', '\\t\\t', 'accuracy','\\t', 'precision-macro \\t', 'recall-macro','\\t', 'f1-macro')\n",
    "eva.caculateMetrix(groundtruth=res_priam_task3.ec_number, predict=res_priam_task3.ec_priam, baselineName='priam', type='multi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "java -jar /home/shizhenkun/codebase/DMLF/baselines/ECPred/ECPred.jar blast /home/shizhenkun/codebase/DMLF/data/datasets/task1/test.fasta /home/shizhenkun/codebase/DMLF/baselines/ECPred/ /home/shizhenkun/codebase/DMLF/results/ecpred\n",
    "\n",
    "java -Xmx128G -jar /home/shizhenkun/codebase/DMLF/baselines/priam/PRIAM_search.jar -p /home/shizhenkun/codebase/DMLF/baselines/priam/PRIAM_JAN18 -i /home/shizhenkun/codebase/DMLF/data/datasets/task1/test.fasta -o /home/shizhenkun/codebase/DMLF/results/priam --blast_path /home/shizhenkun/downloads/blast-2.2.13/bin -np 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0598356972e9a098a4a3756f1f561f75f6bcc730be3bc51870d213558f68c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
